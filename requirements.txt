# Core
fastapi==0.109.0
uvicorn[standard]==0.27.0
gunicorn==21.2.0
pydantic==2.5.3
pydantic-settings==2.1.0

# NLP
spacy==3.7.2
transformers>=4.36.0
torch>=2.0.0
sentencepiece>=0.1.99
huggingface_hub>=0.20.0

# HTTP clients
aiohttp==3.9.1
httpx==0.26.0

# Utils
python-multipart==0.0.6
cachetools==5.3.2

# MamayLM (llama-cpp-python for CPU inference)
# Версия 0.2.70+ поддерживает Gemma 3 архитектуру
llama-cpp-python>=0.2.70

# Testing
pytest==7.4.4
pytest-asyncio==0.23.3
pytest-cov==4.1.0
